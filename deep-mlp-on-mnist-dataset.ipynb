{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3f25313e-6659-4730-b25f-338d56e45904",
    "_uuid": "4d049eac6ef571d212c565362b43950f0d3e0fb0"
   },
   "source": [
    "In this IPython notebook, we will use tflearn,  a deep learning library build on top of tensorflow to build a deep neural network to classify hand written digits in MNIST dataset.\n",
    "\n",
    "We start by importing all required modules namely:\n",
    "- Pandas \n",
    "- tflearn\n",
    "- MNIST dataset from tensorflow.examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "65d61274-1492-42e4-b6ad-ea17f6e08a38",
    "_uuid": "757fac2b0c058cb7a4a3601f8350ae09277bc3de"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tflearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtflearn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexamples\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtutorials\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmnist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_data\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tflearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tflearn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tflearn\n",
      "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
      "     ------------------------------------ 107.3/107.3 kB 693.0 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\computer-_-\\appdata\\roaming\\python\\python38\\site-packages (from tflearn) (1.23.5)\n",
      "Requirement already satisfied: six in c:\\users\\computer-_-\\appdata\\roaming\\python\\python38\\site-packages (from tflearn) (1.16.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\computer-_-\\appdata\\roaming\\python\\python38\\site-packages (from tflearn) (9.3.0)\n",
      "Building wheels for collected packages: tflearn\n",
      "  Building wheel for tflearn (setup.py): started\n",
      "  Building wheel for tflearn (setup.py): finished with status 'done'\n",
      "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127290 sha256=1fd0be83722e10598bcdb525d0e0d0e87e646830b73680dcb31f353cafee3830\n",
      "  Stored in directory: c:\\users\\computer-_-\\appdata\\local\\pip\\cache\\wheels\\65\\9b\\15\\cb1e6b279c14ed897530d15cfd7da8e3df8a947e593f5cfe59\n",
      "Successfully built tflearn\n",
      "Installing collected packages: tflearn\n",
      "Successfully installed tflearn-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d5bca79b-2eb9-44c2-a992-c5546012cb3d",
    "_uuid": "041e1b88fab53828d3f437d092c61bfec14264b9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9e7d7197-c03c-40d4-a7e4-167d335bfb4d",
    "_uuid": "b3c13ceffbb4f8c4ea0eef09371dd480d3987268"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5d12e3df-2cb6-457c-b121-69d54426cda5",
    "_uuid": "a2910d15cc2a8aad143d510218fca592514cb359"
   },
   "source": [
    "Now lets load the dataset from the input folder. We set the one_hot argument as true so that our labels, 0-9, are one hot encoded. \n",
    "\n",
    "We will use the input_data.read_data_sets command from tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "95dd39e4-91f8-49f8-90fd-75c4afdd4bc8",
    "_uuid": "50d87767630bbb7606a4f96af3a8ad759151cd9a"
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('../input/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "003d2342-59cc-4e62-b057-f779728ab247",
    "_uuid": "c5a426c4c2f48ef27469d79ad8f2f7da39d35de5"
   },
   "outputs": [],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "28eb48fa-6065-45a1-a467-ba0ed1de94ff",
    "_uuid": "dc6c3eeb7e2d16c0676379af97aeb069585581a1"
   },
   "source": [
    "Now that we have all our data, we will split it into train, test and validation set. \n",
    "\n",
    "Since **mnist** is a tensorflow dataset object, it has inbuilt splits to help us with this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f3cde181-653d-4d16-9702-21de9dcb169f",
    "_uuid": "fbb5b8c80c1ffb1a2b13572d5f6ee6d534a0bd92"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = mnist.train.images\n",
    "Y =  mnist.train.labels\n",
    "testX =  mnist.test.images\n",
    "testY = mnist.test.labels\n",
    "valX = mnist.validation.images\n",
    "valY = mnist.validation.labels\n",
    "del mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "53fc44d7-016b-43df-96f5-8196cf25a5ce",
    "_uuid": "d7ed8832254d76512e3226e0ab00fa084891ed6b"
   },
   "source": [
    "Now we shall build our deep MLP to classify the images. The key features of this network are as follows:\n",
    "- The input layer accepts multiple arrays of length 784. This is because we have flattened our 28x28 sized images into a single array of length 784(=28*28).\n",
    "- The hidden layers use **relu** activations and regularize all input from last node using **L2** regularisation.\n",
    "- 30 percent **dropout** is also used to prevent overfilling.\n",
    "- The output layer uses **softmax**  function to output prediction classes as a one hot encoded vector.\n",
    "- **Adam** or adaptive momentum optimiser is used.\n",
    "- Top 5 is used as a evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c916f14-8db4-4d21-9a23-e5fa56bafcb4",
    "_uuid": "46dee3f911aa1a80e7d2f4080be54798c61b4836"
   },
   "outputs": [],
   "source": [
    "input_layer = tflearn.input_data(shape=[None, 784])\n",
    "dense1 = tflearn.fully_connected(input_layer, 64, activation='relu',\n",
    "                                 regularizer='L2', weight_decay=0.001)\n",
    "dropout1 = tflearn.dropout(dense1, 0.7)\n",
    "dense2 = tflearn.fully_connected(dropout1, 128, activation='relu',\n",
    "                                 regularizer='L2', weight_decay=0.001)\n",
    "dropout2 = tflearn.dropout(dense2, 0.7)\n",
    "dense3 = tflearn.fully_connected(dropout2, 128, activation='relu',\n",
    "                                 regularizer='L2', weight_decay=0.001)\n",
    "dropout3 = tflearn.dropout(dense2, 0.7)\n",
    "softmax = tflearn.fully_connected(dropout3, 10, activation='softmax')\n",
    "\n",
    "sgd = tflearn.Adam(learning_rate=0.01)\n",
    "top_k = tflearn.metrics.Top_k(5)\n",
    "net = tflearn.regression(softmax, optimizer=sgd, metric=top_k,\n",
    "loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "56acb8f4-504a-453e-a526-27d8a6273c7a",
    "_uuid": "bdd4d9e308b83ed3ccc0d4268f94267b9288a2a0"
   },
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5ff8f884-d91f-4b7a-af8a-afa18065021b",
    "_uuid": "9c9de925dcbc30ca921e06bbc0814aeeff4f457d"
   },
   "source": [
    "Now that out graph is ready, we shall use the fit methord to feed our training and validation sets. The entire training is run for 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e1fe0da7-0028-44fa-a2bb-fa5e1f0e5ac8",
    "_uuid": "afecd5a6bb856e5588c62b11f1b4796f6f79e1d8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, Y, n_epoch=2, validation_set=(testX, testY),show_metric=True, run_id=\"dense_model\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b81a18d0-e1cd-4c85-b8d8-0f1216954e66",
    "_uuid": "2f78b0bca44a1821e8f0a424e84e59de2734dd60"
   },
   "outputs": [],
   "source": [
    "del X\n",
    "del Y\n",
    "del testX\n",
    "del testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "328aede1-47b7-4280-b5f8-5dd3e53dff47",
    "_uuid": "b6e60b3deacd175101319ca21f380a0ef85d9e01"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d1a7f88-acb3-4ce1-9527-a8bcab11fa12",
    "_uuid": "25d956a1d3dea437f5395bc26262f213ace8bbf0"
   },
   "outputs": [],
   "source": [
    "plt.imshow(valX[20].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "545ebe24-4b86-44dd-9ee8-16bef764b108",
    "_uuid": "c6eae6b4928e2ec98528bf2acb8de4b9a81760a9"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(model.predict(valX[20].reshape(1,784)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4ced56af-a867-43db-860e-00a3479d9d63",
    "_uuid": "62438d979570cc9c3e5789395500b326c69a3c80"
   },
   "outputs": [],
   "source": [
    "model.predict_label(valX[20].reshape(1,784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "76b5e531-19c4-4f90-ae69-51691a9a2733",
    "_uuid": "b9c2651e99f11386423c9e499feccb0c8aa69d70"
   },
   "source": [
    "* As we can see the heighest probability is for 4 which is a correct prediction.\n",
    "\n",
    "* The **predict_label** methord also returns 4 as most probable followed by a possibility of 9 and then 7.\n",
    "\n",
    "* Lets evaluate the entire model using the **evaluate** methord of **model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6ac5d800-cbc9-46d8-a76f-10208a18a888",
    "_uuid": "60e740fa8200270ce1babb196bbc5afc58bdd4df"
   },
   "outputs": [],
   "source": [
    "y = model.predict(valX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c5ccb78b-5632-40c8-be75-dab51b38d26c",
    "_uuid": "2e5eaecc18931fe3f9651b3a879db58f56746912"
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "y.shape == valY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "59d0de8b-1f30-413d-8451-dcfaebec3b54",
    "_uuid": "64753680709bdcae7469531f2d882c95fccb8784"
   },
   "outputs": [],
   "source": [
    "model.evaluate(valX,valY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "061344d5-fff7-4302-8860-876b82765b69",
    "_uuid": "89241564299ae906a94ebc70547d1ec3ca72ba50"
   },
   "source": [
    "As we can see the model performs very well and has an accuracy of 99% on unseen validation set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
